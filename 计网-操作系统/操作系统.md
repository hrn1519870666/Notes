#### 什么是操作系统？

**操作系统本质上是一个运行在计算机上的软件程序 ，用于管理计算机硬件和软件资源。** 举例：运行在你电脑上的所有应用程序都通过操作系统来调用系统内存以及磁盘等等硬件。



#### 内核态和用户态

内核态：运行操作系统程序

特权指令：只能由操作系统使用、用户程序不能使用的指令。 举例：启动I/O，  内存清零， 修改程序状态字， 设置时钟

用户态：运行用户程序

非特权指令：用户程序可以使用的指令。 举例：控制转移， 算数运算， 取数指令，  访管指令（使用户程序从用户态陷入内核态）

运行在用户态下的程序不能直接访问操作系统内核数据结构和程序。当我们在系统中执行一个程序时，大部分时间是运行在用户态下的，在其需要操作系统帮助完成某些它没有权力和能力完成的工作时就会切换到内核态。

**用户态到内核态的切换**

**系统调用**

这是用户态进程**主动**要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作。凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

**异常**

当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如**缺页异常**。

**外围设备的中断**

当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令，转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。

**内核态到用户态的切换：**设置程序状态字PSW



#### 进程，线程，协程

进程是操作系统进行资源分配的基本单位，每个进程都有自己的独立内存空间。由于进程比较重量，占据独立的内存，所以进程间上下文切换开销比较大。

线程是处理器任务调度和执行的基本单位。它是比进程更小的能独立运行的基本单位。线程只拥有一点在运行中必不可少的资源(如程序计数器，一组寄存器和栈)，但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。

协程是一种用户态的轻量级线程，协程的调度完全由用户控制（也就是在用户态执行）。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到线程的堆区，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。



#### 进程和线程的区别

- 根本区别：进程是操作系统资源分配的基本单位，而线程是处理器任务调度和执行的基本单位。
- 资源开销：每个进程都有独立的代码和数据空间，进程之间的切换会有较大的开销；线程可以看做轻量级的进程，同一进程的线程共享代码和数据空间，每个线程都有自己独立的运行栈和程序计数器，线程之间切换的开销小。
- 内存分配：同一进程的线程共享本进程的地址空间和资源，而进程之间的地址空间和资源是相互独立的。



#### 线程和协程的区别

![image-20230319141308996](C:\Users\黄睿楠\AppData\Roaming\Typora\typora-user-images\image-20230319141308996.png)



#### 多进程场景

计算密集型的执行任务

原因：充分利用cpu的多核优势，并行计算



#### 多线程场景

IO密集型的执行任务中

原因：I/O密集型场景因为I/O阻塞导致频繁切换，线程只占用栈，程序计数器，一组寄存器等少量资源，切换效率高



#### 什么是上下文切换?

多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。

上下文切换通常是计算密集型的。它需要相当可观的处理器时间，在每秒几十上百次的切换中，每次切换都需要纳秒量级的时间。所以，上下文切换对系统来说意味着消耗大量的 CPU 时间。

Linux 相比与其他操作系统，其上下文切换和模式切换的时间消耗非常少。



#### 进程间通信方式IPC

**消息队列：**

消息队列是消息的链表。消息队列起信箱作用，到了就挂在那里，需要的时候去取。消息队列提供了一种在两个不相关进程间传递数据的简单有效的方法。

**共享内存：**

为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。是**最快**的可用IPC形式。

**信号量：**

信号量是⼀个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。这种通信方式主要应用于解决与同步相关的问题并避免竞争条件。

**匿名管道：**

匿名管道是半双工的，数据只能单向通信；需要双方通信时，需要建立起两个管道；**只能用于父子进程或者兄弟进程之间（具有亲缘关系的进程）。**

**有名管道：**

有名管道实现本机任意两个进程通信，它提供一个路径名，只要可以访问该路径，就能够彼此通过有名管道相互通信。有名管道严格遵循先进先出(first in first out)。

**信号：**

信号是一种比较复杂的通信方式，信号产生的条件：按键、硬件异常、进程调用kill函数将信号发送给另一个进程、用户调用kill命令将信号发送给其他进程，信号传递的消息比较少，主要用于通知接收进程某个事件已经发生。

**套接字(Sockets) :** 

此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信双方的一种约定，用套接字中的相关函数来完成通信过程。



#### 线程间的通信方式

锁（互斥锁，读写锁），信号量，信号



#### select、poll、epoll区别

IO多路复用是一种同步IO模型，一个线程监听多个IO事件，当有IO事件就绪时，就会通知线程去执行相应的读写操作，没有就绪事件时，就会阻塞交出cpu。多路是指网络链接，复用指的是复用同一线程。

**select**

fd_set是一个整型**数组**，用于保存socket文件描述符。

流程：

1. 用户线程调用select，将fd_set从用户空间拷贝到内核空间
2. 内核在内核空间对fd_set遍历一遍，检查是否有就绪的socket描述符，如果没有的话，就会进入休眠，直到有就绪的socket描述符
3. 内核返回select的结果给用户线程，即就绪的文件描述符数量
4. 用户拿到就绪文件描述符数量后，再次对fd_set进行遍历，找出就绪的文件描述符
5. 用户线程对就绪的文件描述符进行读写操作

优点：所有平台都支持，良好的跨平台性

缺点

1. 每次调用select，都需要将fd_set从用户空间拷贝到内核空间，当fd很多时，这个开销很大
2. 将fd_set从用户空间拷贝到内核空间，内核空间也需要对fd_set遍历一遍
3. 每次有活跃的socket描述符时，都需要遍历一次fd_set，造成大量的时间开销，时间复杂度是O(n)
4. 最大连接数（支持的最大文件描述符数量）有限制，一般为1024



**poll**

执行过程（基本与select相同）

1. 用户线程调用poll系统调用，并将文件描述符**链表**拷贝到内核空间
2. 内核对文件描述符遍历一遍，如果没有就绪的描述符，则内核开始休眠，直到有就绪的文件描述符
3. 返回给用户线程就绪的文件描述符数量
4. 用户线程再遍历一次文件描述符链表，找出就绪的文件描述符
5. 用户线程对就绪的文件描述符进行读写操作

与select的异同点

相同点：

1. 内核线程都需要遍历文件描述符，并且当内核返回就绪的文件描述符数量后，用户线程还需要遍历一次找出就绪的文件描述符
2. 需要将文件描述符数组或链表从用户空间拷贝到内核空间
3. 性能开销会随文件描述符的数量而线性增大

不同点：

1. select存储的数据结构是文件描述符数组，poll采用链表
2. select有最大连接数限制，poll没有最大限制，因为poll采用链表存储



**epoll**

核心点

1. epoll_create创建eventpoll对象（红黑树，双向链表）
2. 一棵红黑树，存储**监听的所有文件描述符**，并且通过epoll_ctl将文件描述符添加、删除到红黑树
3. 一个双向链表，存储**就绪的文件描述符列表**，epoll_wait调用时，检测此链表中是否有数据，有的话直接返回
4. 所有添加到eventpoll中的事件都与设备驱动程序建立回调关系

优点

1. 时间复杂度为O(1)，当有事件就绪时，epoll_wait只需要检测就绪链表中有没有数据，如果有的话就直接返回
2. 不需要从用户空间到内核空间频繁拷贝文件描述符集合，使用了内存映射(mmap)技术
3. 当有就绪事件发生时采用回调的形式通知用户线程

缺点：只能工作在linux下



![image-20230319175357347](C:\Users\黄睿楠\AppData\Roaming\Typora\typora-user-images\image-20230319175357347.png)



`select` 只支持水平触发，`epoll` 支持水平触发和边缘触发。

水平触发（LT，Level Trigger）：当文件描述符就绪时，会触发通知，如果用户程序没有一次性把数据读/写完，下次还会发出可读/可写信号进行通知。

边缘触发（ET，Edge Trigger）：仅当描述符从未就绪变为就绪时，通知一次，之后不会再通知。

区别：边缘触发效率更高，**减少了事件被重复触发的次数**，函数不会返回大量用户程序可能不需要的文件描述符。

**适用场景**

当连接数较多并且有很多的不活跃连接时，epoll 的效率比其它两者高很多。当连接数较少并且都十分活跃的情况下，由于 epoll 需要很多回调，因此性能可能低于其它两者。

[I/O 多路复用，select / poll / epoll 详解](https://imageslr.com/2020/02/27/select-poll-epoll.html)



#### 产生死锁必须具备的四个条件？

1. 互斥：该资源任意一个时刻只由一个线程占用。

2. 不可剥夺:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，**只有自己使用完毕后才释放资源。**

3. 请求并保持：一个进程因请求资源而阻塞时，对已获得的资源保持不放。

4. 循环等待:若干进程之间形成一种头尾相接的循环等待资源关系。

   系统中拥有两个进程P1和P2，它们都准备写两个文件F1和F2。而这两者都属于可重用和不可抢占性资源。如果进程P1在打开F1的同时，P2进程打开F2文件，当P1想打开F2时由于F2已经被占用而阻塞，当P2想打开1时由于F1已经被占用而阻塞，此时就会无线等待下去，形成死锁。

   ![img](https://img2020.cnblogs.com/blog/2034687/202108/2034687-20210822153244554-1001320523.png)



#### 如何避免线程死锁?

1.**破坏不可剥夺条件** ：占用部分资源的线程进一步申请其他资源时，**如果申请不到，可以主动释放它占有的资源。**

2.**破坏请求与保持条件** ：一次性申请所有的资源。

3.**破坏循环等待条件** ：资源按序申请。



#### 死锁的例子

```java
public class DeadLock {
 
    public static Object t1 = new Object();
    public static Object t2 = new Object();
 
    public static void main(String[] args){
        // 线程1
        new Thread(){
            @Override
            public void run(){
                synchronized (t1){
                    System.out.println("Thread1 get t1");
 
                    try {
                        Thread.sleep(100);
                    }catch (Exception e){
                        e.printStackTrace();
                    }
 					// 在synchronized (t1)代码块内部，执行synchronized (t2)
                    synchronized (t2){
                        System.out.println("Thread1 get t2");
                    }
                }
            }
        }.start();
        
 		// 线程2
        new Thread(){
            @Override
            public void run(){
                synchronized (t2){
                    System.out.println("Thread2 get t2");
 
                    try {
                        Thread.sleep(100);
                    }catch (Exception e){
                        e.printStackTrace();
                    }
 
                    synchronized (t1){
                        System.out.println("Thread2 get t1");
                    }
                }
            }
        }.start();
    }
```

输出：

```
Thread1 get t1
Thread2 get t2
```

对线程 2 的代码修改成下面这样就不会产生死锁了：

```java
	// 线程2
    new Thread(){
        @Override
        public void run(){
            // 先锁t1
            synchronized (t1){
                System.out.println("Thread2 get t1");
 
                try {
                    Thread.sleep(100);
                }catch (Exception e){
                    e.printStackTrace();
                }
 
                synchronized (t2){
                    System.out.println("Thread2 get t2");
                }
            }
        }
    }.start();
}
```

输出

```
Thread1 get t1
Thread1 get t2
Thread2 get t1
Thread2 get t2
```

线程 1 首先获得到t1的锁，然后再去获取t2的监视器锁，可以获取到。然后线程 1 释放了对t1、t2的锁的占用，线程 2 获取到就可以执行了。**破坏了循环等待条件，**因此避免了死锁。



#### 内存管理方式，分页分段以及段页式的优缺点 

**内存管理方式：**简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。

**分页管理：**

​		在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的页框，程序加载时，可以将任意一页放入内存中任意一个页框，这些页框不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）

**分段管理：**

​		在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）

**段页式管理：**

​		段⻚式管理机制就是把主存先分成若⼲段，每个段⼜分成若⼲⻚，也就是说段⻚式管理机制中段与段之间以及段的内部的都是离散的。



#### 分页机制和分段机制的共同点和区别

1. **共同点** ：
   - 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。
   - 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。
2. **区别** ：
   - 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
   - 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。



#### 什么是虚拟内存

虚拟内存使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。



#### 虚拟内存的技术实现

 虚拟内存的实现有以下三种方式：

1. **请求分页存储管理** ：建立在分页管理之上，为了支持虚拟存储器功能而增加了请求调页功能和页面置换功能。请求分页是目前最常用的一种实现虚拟存储器的方法。请求分页存储管理系统中，在作业开始运行之前，仅装入当前要执行的部分页即可运行。假如在作业运行的过程中发现要访问的页面不在内存，则由处理器通知操作系统按照对应的页面置换算法将相应的页面调入到主存，同时操作系统也可以将暂时不用的页面置换到外存中。
2. **请求分段存储管理** ：建立在分段存储管理之上，增加了请求调段功能、分段置换功能。请求分段储存管理方式就如同请求分页储存管理方式一样，在作业开始运行之前，仅装入当前要执行的部分段即可运行；在执行过程中，可使用请求调入中断动态装入要访问但又不在内存的程序段；当内存空间已满，而又需要装入新的段时，根据置换功能适当调出某个段，以便腾出空间而装入新的段。
3. **请求段页式存储管理**

**请求分页与分页存储管理有何不同呢？**

根本区别在于是否将一作业的全部地址空间同时装入主存。请求分页存储管理不要求将作业全部地址空间同时装入主存。基于这一点，请求分页存储管理可以提供虚存，而分页存储管理却不能提供虚存。



#### 页面置换算法有哪些

**先进先出FIFO:**

​		原理：把内存中驻留时间最久的页面予以淘汰

​		优点：实现简单、直观

​		缺点：没有考虑到实际的页面使用频率，性能差、与通常页面使用的规则不符合，实际应用较少

**最近最久未使用LRU:**

​		原理：选择最近且最久未使用的页面进行淘汰

​		优点：考虑到了程序访问的时间局部性，有较好的性能，实际应用也比较多

​		缺点：实现需要比较多的硬件支持，会增加一些硬件成本



### BIO,NIO,AIO

#### 阻塞与非阻塞

阻塞与非阻塞指的是**单个线程内遇到同步等待时，是否在原地不做任何操作。**

阻塞指的是遇到同步等待后，一直在原地等待同步方法处理完成。

非阻塞指的是遇到同步等待，不在原地等待，先去做其他的操作，隔一段时间再来观察同步方法是否完成。



#### 同步与异步

同步和异步指的是**一个执行流程中每个方法是否必须依赖前一个方法完成后才可以继续执行。假设我们的执行流程中，依次是方法一和方法二。**

同步指的是调用一旦开始，调用者必须等到方法调用返回后，才能继续后续的行为。即方法二要等到方法一执行完成后才可以执行。

异步指的是调用立刻返回，调用者不必等待方法内的代码执行结束，就可以继续后续的行为。（具体方法内的代码交由另外的线程执行完成后，可能会进行回调）。即执行方法一的时候，直接交给其他线程执行，不由主线程执行，也就不会阻塞主线程，所以方法二不必等到方法一完成即可开始执行。



**BIO (Blocking I/O): 同步阻塞 I/O 模型，**应用程序发起 read 调用后，会一直阻塞，直到内核把数据拷贝到用户空间。

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6a9e704af49b4380bb686f0c96d33b81~tplv-k3u1fbpfcp-watermark.image" alt="图源：《深入拆解Tomcat & Jetty》" style="zoom:50%;" />

在客户端连接数量不高的情况是没问题的。但是，当面对十万甚至百万级连接的时候，传统的 BIO 模型是无能为力的。



**NIO (Non-blocking/New I/O): 同步非阻塞 I/O 模型，**也可以看作是 **I/O 多路复用模型**。

我们先来看看 **同步非阻塞 IO 模型**。

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bb174e22dbe04bb79fe3fc126aed0c61~tplv-k3u1fbpfcp-watermark.image" alt="图源：《深入拆解Tomcat & Jetty》" style="zoom:50%;" />

同步非阻塞 IO 模型中，应用程序会一直发起 read 调用，等待数据从内核空间拷贝到用户空间的这段时间里，线程依然是阻塞的，直到在内核把数据拷贝到用户空间。

相比于BIO，NIO通过**轮询**操作，避免了一直阻塞。

但是，这种 IO 模型同样存在问题：**应用程序不断轮询数据是否已经准备好的过程是十分消耗 CPU 资源的。**

这个时候，**I/O 多路复用模型** 就上场了。

<img src="https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/88ff862764024c3b8567367df11df6ab~tplv-k3u1fbpfcp-watermark.image" alt="img" style="zoom:50%;" />

IO 多路复用模型中，线程首先发起 select 调用，询问内核数据是否准备就绪，等内核把数据准备好了，用户线程再发起 read 调用。read 调用的过程（数据从内核空间 -> 用户空间）还是阻塞的。

**IO 多路复用模型，通过减少无效的轮询，减少了对 CPU 资源的消耗。**

NIO 有一个非常重要的**选择器 ( Selector )** 的概念，也可以被称为 **多路复用器**。通过它，只需要一个线程便可以管理多个客户端连接。当客户端数据到了之后，才会为其服务。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/0f483f2437ce4ecdb180134270a00144~tplv-k3u1fbpfcp-watermark.image)



**AIO (Asynchronous I/O):又称NIO2， 异步非阻塞的 IO 模型。**

异步 IO 是基于事件和回调机制实现的，也就是应用操作之后会直接返回，不会堵塞在那里，当后台处理完成，操作系统会通知相应的线程进行后续的操作。

<img src="https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/3077e72a1af049559e81d18205b56fd7~tplv-k3u1fbpfcp-watermark.image" alt="img" style="zoom:50%;" />

总结对比：

<img src="https://images.xiaozhuanlan.com/photo/2020/33b193457c928ae02217480f994814b6.png" alt="img" style="zoom:50%;" />
